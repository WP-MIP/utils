#!/gpfs/fs3c/eccc/mrd/rpnatm/swpm001/installed/venv/bin/python
import glob, os, re, sys, calendar, shutil, glob, errno
from datetime import datetime
from collections import defaultdict
import earthkit as ek

# Contributor name mapping
namemap = defaultdict(dict)
namemap = dict({'cwao':{'name':'ECCC', 'long':'ECCC'},
                'ecmf':{'name':'ECMWF', 'long':'ECMWF'},
                'kwbc':{'name':'NOAA', 'long':'NOAA'},
                'rksl':{'name':'KMA/KIAPS', 'long':'KMA_KIAPS'},
                'ammc':{'name':'BoM', 'long':'BoM'},
                'babj':{'name':'CMA', 'long':'CMA'},
                'sbsj':{'name':'CPTEC/INPE', 'long':'CPTEC_INPE'},
                'edzw':{'name':'DWD', 'long':'DWD'},
                'vabb':{'name':'IMD', 'long':'IMD'},
                'rjtd':{'name':'JMA', 'long':'JMA'},
                'egrr':{'name':'UKMO', 'long':'UKMO'},
                'enmi':{'name':'MetNo', 'long':'MetNo'},
                'gfdl':{'name':'GFDL', 'long':'GFDL'},
                'rums':{'name':'RAS', 'long':'RAS'}})

# Variable name mapping
varmap = {'pl':defaultdict(dict), 'sl':defaultdict(dict)}
varmap['pl'] = dict({'t':{'long':'Temperature', 'units':'K', 'id':'130'},
                     'q':{'long':'Specific Humidity', 'units':'kg kg<sup>-1</sup>', 'id':'133'},
                     'u':{'long':'U-Component Wind', 'units':'m s<sup>-1</sup>', 'id':'131'},
                     'v':{'long':'V-Component Wind', 'units':'m s<sup>-1</sup>', 'id':'132'},
                     'gh':{'long':'Geopential Height', 'units':'m', 'id':'156'}})
varmap['sl'] = dict({'msl':{'long':'Mean Sea Level Pressure', 'units':'Pa', 'id':'151'},
                     'sp':{'long':'Surface Pressure', 'units':'Pa', 'id':'134'},
                     '2t':{'long':'Screen-Level Temperature', 'units':'K', 'id':'167'},
                     '2sh':{'long':'Screen-Level Specific Humidity', 'units':'kg kg<sup>-1</sup>', 'id':'174096'},
                     '2d':{'long':'Screen-Level Dewpoint', 'units':'K', 'id':'168'},
                     'sst':{'long':'Sea Surface Temperature', 'units':'K', 'id':''},
                     '10u':{'long':'Anemometer-Level U-Component Wind', 'units':'m s<sup>-1</sup>', 'id':'165'},
                     '10v':{'long':'Anemometer-Level V-Component Wind', 'units':'m s<sup>-1</sup>', 'id':'166'},
                     'tp':{'long':'Precipitation Accumulation', 'units':'kg m<sup>-2</sup>', 'id':'228228'},
                     'ci':{'long':'Sea Ice Fraction', 'units':'', 'id':'31'},
                     'sithick':{'long':'Sea Ice Thickness', 'units':'m', 'id':'174098'},
                     'tcc':{'long':'Total Cloud Cover', 'units':'%', 'id':'228164'},
                     'lcc':{'long':'Low Cloud Cover', 'units':'%', 'id':'3073'},
                     'mcc':{'long':'Mid Cloud Cover', 'units':'%', 'id':'3074'},
                     'hcc':{'long':'High Cloud Cover', 'units':'%', 'id':'3075'},
                     'ssr':{'long':'Surface Net Shortwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'176'},
                     'ssrd':{'long':'Surface Downwelling Shortwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'169'},
                     'str':{'long':'Surface Net Longwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'175'},
                     'strd':{'long':'Surface Downwelling Longwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'177'},
                     'tsr':{'long':'TOA Net Shortwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'178'},
                     'tisr':{'long':'TOA Downwelling Shortwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'179'},
                     'ttr':{'long':'TOA Net Longwave Accumulation', 'units':'J m<sup>-2</sup>', 'id':'212'},
                     'sshf':{'long':'Time-Integrated Surface Sensible Heat Flux', 'units':'J m<sup>-2</sup>', 'id':'146'},
                     'slhf':{'long':'Time-Integrated Surface Latent Heat Flux', 'units':'J m<sup>-2</sup>', 'id':'147'},
                     'lsm':{'long':'Land-Sea Mask', 'units':'', 'id':'172'},
                     'orog':{'long':'Orography', 'units':'m', 'id':'228002'}})

# Level name mapping
levmap = {'sl':'Single-Level', 'pl':'Pressure-Level'}

# Model type name mapping
typemap = {'ai':'AI', 'hy':'Hybrid', 'pm':'Physical'}

# Level value mapping
levsmap = {'sl':[1], 'pl':[1000, 925, 850, 700, 500, 400, 300, 250, 200, 150, 100, 50, 10]}
                    
# Basic setup
exp = 'WP-MIP'
base = os.path.join('/home/swpm001/public_html', exp)
fbase = os.path.join(base, 'forecasts')
html_path = '/home/swpm001/public_html'
sptable_path = os.path.join(html_path, 'sp.tbl')
vindex = 'vindex'
indexdir = os.path.join(html_path, exp, vindex)
test_pl = ['t']
test_sl = ['2t', 'msl']
sp1_threshold = 1000
model_defaults = defaultdict(dict)
model_defaults = dict({'ai':{'link':'-', 'path':[]},
                       'hy':{'link':'-', 'path':[]},
                       'pm':{'link':'-', 'path':[]}})
analysis_defaults = dict({'pm':{'link':'-', 'path':[]}})


class Contrib(dict):
    """Class handling contribution-centric archive layout"""

    def __init__(self, base, stream):
        contrib_pl = self._getContrib(base, stream, 'pl', test_pl)
        contrib_sl = self._getContrib(base, stream, 'sl', test_sl)    
        contrib = self._joinContrib(contrib_pl, contrib_sl, stream)
        outstr = ''
        paths = []
        for centre in sorted(contrib.keys()):
            try:
                name = namemap[centre]['name']
            except KeyError:
                name = centre
            c = contrib[centre]
            outstr += '<tr><td>'+centre+'</td><td>'+name+self._addtd(c['pl'])+self._addtd(c['sl'])+'\n'
            paths.extend(self._addpath(c['pl']))
            paths.extend(self._addpath(c['sl']))
        self.outstr = outstr
        allpaths = []
        for p in paths:
            if p:
                allpaths.extend(p)
        self.paths = sorted(set(allpaths))
        self.sptbl = self._subprojects(base)

    def _getDirs(self, base, wild, testfld):
        dirsall = [glob.glob(os.path.join(base, wild, fld), recursive=True) for fld in testfld]
        dlist = []
        for dirs in dirsall:
            dlist.extend([os.path.dirname(d) for d in dirs])
        return(set(dlist))
        
    def _getContrib(self, base, stream, lev, testfld):
        if not os.path.exists(base):
            sys.stderr.write('Cannot find '+base+'.  Run this application from the hpfx server.\n')
            sys.exit(1)
        if stream is None:
            dirs = self._getDirs(base, '*', testfld)
            contrib = {}
            for dir in dirs:
                path = re.split('/', dir)
                centre = path[-1]
                path = os.path.join(exp, os.path.basename(base), centre)
                linkpath = os.path.join(path, 'index_'+lev+'.html')
                if centre not in contrib.keys():
                    contrib[centre] = defaultdict(dict)
                contrib[centre] = {'pm':{'link':'<a href="'+linkpath+'">Available</a>', 'path':[path]}}
            for centre in contrib.keys():
                contrib[centre] = dict(contrib[centre])
        else:
            dirs = self._getDirs(os.path.join(base, stream), '*/*', testfld)
            contrib = {}
            for dir in dirs:
                path = re.split('/', dir)
                (ty, ver) = re.split('_', path[-1])
                centre = path[-2]
                path = os.path.join(exp, os.path.basename(base), stream, centre, ty+'_'+ver)
                linkpath = os.path.join(path, 'index_'+lev+'.html')
                if centre not in contrib.keys():
                    contrib[centre] = defaultdict(dict)
                try:
                    contrib[centre][ty]['link'] += ', <a href="'+linkpath+'">v'+ver+'</a>'
                    contrib[centre][ty]['path'].append(path)
                except KeyError:
                    contrib[centre][ty] = defaultdict(dict)
                    contrib[centre][ty] = {'link':'<a href="'+linkpath+'">v'+ver+'</a>', 'path':[path]}
            for centre in contrib.keys():
                for ty in model_defaults.keys():
                    if ty not in contrib[centre]:
                        contrib[centre][ty] = {'link':'-', 'path':[]}
                contrib[centre] = dict(contrib[centre])
        return(dict(contrib))

    def _joinContrib(self, cpl, csl, stream):
        defaults = analysis_defaults if stream == None else model_defaults
        contrib = {}
        for centre in set(list(cpl.keys()) + list(csl.keys())):
            try:
                pl = cpl[centre]
            except KeyError:
                pl = defaults
            try:
                sl = csl[centre]
            except KeyError:
                sl = defaults
            contrib[centre] = {'pl':pl, 'sl':sl}
        return(contrib)

    def _addtd(self, d):
        tdstr = ''
        for ty in sorted(model_defaults):
            try:
                tdstr += '<td style="text-align: center;">'+d[ty]['link']+'</td>'
            except KeyError:
                pass
        return(tdstr)

    def _addpath(self, p):
        paths = []
        for ty in model_defaults:
            try:
                paths.append(p[ty]['path'])
            except KeyError:
                pass
        return(paths)

    def _subprojects(self, htmlbase):
        import pathlib
        sptbl = {}
        fbase = os.path.join('/', *re.split('/', htmlbase)[:-2])
        for contrib in self.paths:
            p = pathlib.Path(os.path.join(fbase, contrib))
            subdirs = sorted([x for x in p.iterdir() if x.is_dir()])
            testfile = sorted(list(subdirs[0].glob("*.grib2")))[0]
            ds = ek.data.from_source('file', testfile)
            sp = 'core'
            if len(set(ds.metadata("julianDay"))) > 20: sp = ','.join([sp, 'sp1'])
            if max(ds.metadata("step")) > 240: sp = ','.join([sp, 'sp2'])
            sptbl[contrib] = sp
        return(sptbl)
    
class varPage(dict):
    """Class handling variable-centric reshaping of the archive"""

    def __init__(self, fpath):
        self["flist"] = [fpath]
        path = re.split('/', fpath)
        self["prod"] = path[0]
        self["varname"] = path[-2]
        fname = path[-1]
        if re.search('_pl_', fname):
            self["levty"] = 'pl'
            lev = int(re.split('_', fname)[1])
            if lev in levsmap[self["levty"]]: 
                self["lev"] = int(re.split('_', fname)[1])
            else:
                raise ValueError
        else:
            self["levty"] = 'sl'
            self["lev"] = 1

    def pagePath(self):
        return(os.path.join(html_path, self.pageLink()))
                                        
    def pageLink(self):
        return(os.path.join(exp, vindex, self["varname"], str(self["lev"]), 'index_'+self["prod"]+'.html'))
                            
    def add(self, new):
        self["flist"].extend(new["flist"])

    def buildLinks(self):
        indexdir = os.path.dirname(self.pagePath())
        os.makedirs(indexdir, exist_ok=True)
        for dfile in self["flist"]:
            fn = os.path.basename(dfile)
            self._symlinkf(os.path.join(base, dfile), os.path.join(indexdir, fn))  
            
    def buildPage(self):
        os.makedirs(os.path.dirname(self.pagePath()), exist_ok=True)
        table = []
        for fn in self["flist"]:
            table.append(self._tableRow(self._fileInfo(fn)))
        tablestr = '\n'.join(sorted(table))
        prefix = '<center><h1>WP-MIP'
        if self["levty"] == 'pl':
            prefix += ' '+str(self["lev"])+' hPa'
        titlestr = ' '.join([prefix,varmap[self["levty"]][self["varname"]]['long'], \
                           self["prod"].capitalize()])
        titlestr += '</h1></center>'
        filestr = self._fntemplate()
        eginfo = self._fileInfo(self["flist"][0])
        with open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/index_byvar_var.tmpl'), "rt") as fdin:
            with open(self.pagePath(), "wt") as fdout:
                for line in fdin:
                    line = std_replace(line, title=titlestr, prod=self["prod"])
                    line = line.replace('VARLONG', varmap[self["levty"]][self["varname"]]['long'].lower())
                    line = line.replace('VARCAP', varmap[self["levty"]][self["varname"]]['long'])
                    line = line.replace('FILESTR', filestr)
                    line = line.replace('VARPATH', os.path.dirname(self.pageLink()))
                    line = line.replace('CONTR4', eginfo["centre"])
                    line = line.replace('CONTRIBUTOR', namemap[eginfo["centre"]]['name'])
                    line = line.replace('GRIBID', varmap[self["levty"]][self["varname"]]['id'])
                    line = line.replace('TABLE_DATA', tablestr)
                    fdout.write(line)

    def _tableRow(self, info):
        tdc = '</td><td  style="text-align: center;">'
        fname = os.path.basename(info["fname"])
        return('<tr><td><a href="'+fname+'">'+fname+'</a>'+tdc+info["stream"].upper()+tdc+ \
               namemap[info["centre"]]["name"]+tdc+typemap[info["ty"]]+tdc+str(info["ver"])+tdc+ \
               calendar.month_name[info["mon"]]+' '+str(info["year"])+'</td></tr>')

    def _fileInfo(self, fn):
        path = re.split('/', fn)
        if self["prod"] == "analyses":
            stream = 'Analysis'
            centre = path[1]
            ty = 'pm'
            ver = 0
        else:
            stream = path[1]
            centre = path[2]
            (ty, ver) = re.split('_', path[3])
        mon = int(re.split('[_\.]', fn)[-2])
        year = 2024
        while mon > 12:
            year += 1
            mon -= 12
        return({'stream':stream, 'centre':centre, 'ty':ty, 'ver':ver, 'mon':mon, 'year':year, 'fname':fn})
               
    def _symlinkf(self, target, link):
        try:
            os.symlink(target, link)
        except FileExistsError:
            rtarget = os.path.realpath(target)
            rlink = os.path.realpath(link)
            if rlink != rtarget:
                sys.stderr.write('Error: link/target mismatch.\n  Link:   '+rlink+'\n  Target: '+rtarget+'\n')
                raise

    def _fntemplate(self):
        fsplit = re.split('_', os.path.basename(self["flist"][0]))
        fsplit[-1] = 'NN.grib2'
        if self["prod"] == 'analyses':
            fsplit[-3] = 'CCCC'
        else:
            fsplit[-6] = 'SSS'
            fsplit[-5] = 'CCCC'
            fsplit[-4] = 'MM'
            fsplit[-3] = 'II'
        return('_'.join(fsplit))

def varid(varname, lev, prod):
    return('_'.join([varname, str(lev), prod]))

def varList():
    vlist = {}
    for prod in ['analyses', 'forecasts']:
        for file in glob.iglob(os.path.join(prod, '**', '*.grib2'), root_dir=base, recursive=True):
            try:
                vpg = varPage(file)
            except ValueError:
                continue
            try:
                vlist[varid(vpg["varname"], vpg["lev"], prod)].add(vpg)
            except KeyError:
                vlist[varid(vpg["varname"], vpg["lev"], prod)] = vpg
    return(vlist)

def varLinks(vlist):
    [vpg.buildLinks() for vpg in vlist.values()]

def varPages(vlist):
    [vpg.buildPage() for vpg in vlist.values()]

def varTable(vlist, prod, lev):
    tbl = []
    for var in varmap[lev].keys():
        tdc = '<td style="text-align: center;">'
        vtbl = ''
        if lev == 'sl':
            try:
                hlinks = '<a href="'+vlist[varid(var, 1, prod)].pageLink()+'">'
                hlinke = '</a>'
            except KeyError:
                continue
        else:
            hlinks = ''
            hlinke = ''
        vtbl += '<tr><td>'+hlinks+varmap[lev][var]['long']+hlinke+'</td>'+tdc+var+'</td>'+tdc+ \
            varmap[lev][var]['units']+'</td>'
        if lev == 'pl':
            vtbl += tdc+', '.join(map(lambda v: '<a href="'+vlist[varid(var, v, prod)].pageLink()+'">'+ \
                                     str(v)+'</a>', levsmap[lev]))+'</td>'
        vtbl += '</tr>\n'
        tbl.append(vtbl)
    return('\n'.join(sorted(tbl)))

def pathIndex(paths):
    inlines = {}
    for pagelev in ['model', 'var']:
        fdin = open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/index_'+pagelev+'.tmpl'), "rt")
        inlines[pagelev] = fdin.readlines()
        fdin.close()
    for p in paths:
        pitems = re.split('/', p)
        if pitems[-2] == 'analyses':
            offset = 1
            ty = 'pm'
            prod = 'analyses'
        else:
            offset = 0
            ty = re.split('_', pitems[-1])[0]
            prod = 'forecasts'
        centre = pitems[-2 + offset]
        stream = pitems[-3 + offset]
        fullpath = os.path.join(html_path, p)
        dlist = [dir for dir in os.scandir(fullpath) if os.path.isdir(dir)]
        for lev in levmap.keys():
            tline = ''
            vars = [dir for dir in sorted(dlist, key=lambda dir: dir.name) if dir.name in varmap[lev].keys()]
            for var in vars:
                
                # Variable-level page showing available files
                varpath = os.path.join(fullpath, var.name)                
                if lev == 'sl':
                    files = [fn for fn in sorted(os.scandir(varpath), key=lambda file: file.name) if re.search('grib2', fn.name)]
                else:
                    flist = []
                    for file in [fn for fn in os.scandir(varpath) if re.search('grib2', fn.name)]:
                        fsplit = re.split('_', file.name)
                        icode = int(fsplit[1])*100 + int(re.split('\.', fsplit[-1])[0])
                        flist.append({'file':file, 'code':icode})
                    files = [fn['file'] for fn in sorted(flist, key=lambda file: file['code'])]
                fline = ''
                for fn in files:
                    fsplit = re.split('_', fn.name)
                    mon = int(re.split('\.', fsplit[-1])[0])
                    year = 2024
                    while mon > 12:
                        year += 1
                        mon -= 12
                    if lev == 'pl':
                        slev = fsplit[1]
                        fline += '<tr><td><a href='+fn.name+'>'+fn.name+'</a></td><td>'+slev+'</td><td>'+ \
                            calendar.month_name[mon]+' '+str(year)+'</td>'
                    else:
                        fline += '<tr><td><a href='+fn.name+'>'+fn.name+'</a></td><td>'+calendar.month_name[mon]+' '+str(year)+'</td>'
                with open(os.path.join(varpath, 'index_var.html'), "w") as fdvar:
                    if prod == 'analyses':
                        titlestr = ' '.join(['<center><h1>', namemap[centre]['long'], varmap[lev][var.name]['long'], \
                                             prod.capitalize(), '</h1></center>'])
                    else:
                        titlestr = ' '.join(['<center><h1>', namemap[centre]['long'], typemap[ty], 'Model', \
                                             varmap[lev][var.name]['long'], prod.capitalize(), '('+stream.upper()+')', '</h1></center>'])
                    fsplit = re.split('_', fn.name)
                    leveg = ''
                    levwild = ''
                    levinst = ''
                    levcol = ''
                    if lev == 'pl':
                        fsplit[1] = 'LEV'
                        leveg = 'lev=500      #e.g. retrieve 500 hPa level'
                        levwild = '*_${lev}_'
                        levinst = 'levels (LEV) and'
                        levcol = '<th>Level (hPa)</th>'
                    fsplit[-1] = 'MM.grib2'
                    filestr = '_'.join(fsplit)
                    linkstr = re.sub(base+'/', '', varpath)
                    for line in inlines['var']:
                        line = std_replace(line, title=titlestr, prod=prod, centre=centre)
                        line = line.replace('VARLONG', varmap[lev][var.name]['long'].lower())
                        line = line.replace('VARCAP', varmap[lev][var.name]['long'])
                        line = line.replace('FILESTR', filestr)
                        line = line.replace('MODEL_TYPE', typemap[ty])
                        line = line.replace('GRIBID', varmap[lev][var.name]['id'])
                        line = line.replace('LEV_COL', levcol)
                        line = line.replace('LEV_INST', levinst)
                        line = line.replace('LEV_EXAMPLE', leveg)
                        line = line.replace('LEV_WILD', levwild)
                        line = line.replace('VARPATH', linkstr)
                        line = line.replace('TABLE_DATA', fline)
                        fdvar.write(line)
                        
                # Table line for model-level page
                tline += '<tr><td><a href='+var.name+'/index_var.html>'+varmap[lev][var.name]['long']+'</a></td><td>'+var.name+'</td>'+ \
                    '<td>'+varmap[lev][var.name]['units']+'</td></tr>\n'

            # Model-level page showing available variables
            with open(os.path.join(fullpath, 'index_'+lev+'.html'), "w") as fdmod:
                if prod == 'analyses':
                    titlestr = ' '.join(['<center><h1>', namemap[centre]['long'], levmap[lev], prod.capitalize(), '</h1></center>'])
                else:
                    titlestr = ' '.join(['<center><h1>', namemap[centre]['name'], levmap[lev], typemap[ty],
                                         'Model Forecasts','('+stream.upper()+')','</h1></center>'])
                for line in inlines['model']:
                    line = std_replace(line, title=titlestr, prod=prod, centre=centre)
                    line = line.replace('TABLE_DATA', tline)
                    line = line.replace('MODEL_TYPE', typemap[ty])
                    fdmod.write(line)

def writeSpTable(tbl, oictbl, sictbl):
    with open(tbl, "w") as fdout:
        for (k, v) in (oictbl | sictbl).items():
            fdout.write(' '.join([k, v, '\n']))
                    
def std_replace(line, title=None, prod=None, centre=None):
    global licence_text, portal_header
    if 'licence_text' not in globals():
        with open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/licence.html'), "rt") as fdin:
            licence_text = fdin.read()
    if 'portal_header' not in globals():
        with open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/portal_header.html'), "rt") as fdin:
            portal_header = fdin.read()
    edit_warning = '<!-- THIS FILE IS AUTOMATICALLY GENERATED BY THE genindex TOOL.  DO NOT EDIT THIS FILE!!! -->'
    lineo = line
    lineo = lineo.replace('PORTAL_HEADER', portal_header)
    lineo = lineo.replace('GEN_DATETIME', datetime.utcnow().strftime('%H%M UTC %d %h %Y'))
    lineo = lineo.replace('EDIT_WARNING', edit_warning)
    lineo = lineo.replace('LICENCE_TEXT', licence_text)
    if title: lineo = lineo.replace('TITLE', title)
    if prod: lineo = lineo.replace('PRODLOWER', prod)
    if prod: lineo = lineo.replace('PRODCAP', prod.capitalize())
    if centre: lineo = lineo.replace('CENTRELONG', namemap[centre]['long'])
    if centre: lineo = lineo.replace('CENTRENAME', namemap[centre]['name'])
    return(lineo)


### Generic Tools ###

# Generate data portal landing pad
with open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/index.tmpl'), "rt") as fdin:
    with open(os.path.join(html_path, "index.html"), "wt") as fdout:
        for line in fdin:
            line = std_replace(line)
            fdout.write(line)

# Copy ancillary file to destination
shutil.copy(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/styles2.css'), os.path.dirname(base))
shutil.copy(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/wpmip_logo-1_small.png'), os.path.dirname(base))

                    
### Contribution-based Tools ###
                    
# OIC Contributions
oic = Contrib(fbase, 'oic')

# SIC Contributions
sic = Contrib(fbase, 'sic')

# Available analyses
anl = Contrib(os.path.join(base, 'analyses'), None)

# Create new contributor index file
with open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/index_contrib.tmpl'), "rt") as fdin:
    with open(os.path.join(html_path, "index_contrib.html"), "wt") as fdout:
        for line in fdin:
            line = std_replace(line)
            line = line.replace('OIC_TABLE_DATA', oic.outstr)
            line = line.replace('SIC_TABLE_DATA', sic.outstr)
            line = line.replace('ANALYSES_TABLE_DATA', anl.outstr)
            fdout.write(line)

# Generate the subproject table
writeSpTable(sptable_path, oic.sptbl, sic.sptbl)
            
# Create model-specific index files
pathIndex(oic.paths)
pathIndex(sic.paths)
pathIndex(anl.paths)


### Variable-based Tools ###

# Get variable-listed set of files
vlist = varList()

# Create links in variable-listed index
varLinks(vlist)

# Create variable-specific pages
varPages(vlist)

# Create new variable index file
with open(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'etc/index_byvar.tmpl'), "rt") as fdin:
    with open(os.path.join(html_path, "index_byvar.html"), "wt") as fdout:
        for line in fdin:
            line = std_replace(line)
            line = line.replace('FCSTPL_TABLE_DATA', varTable(vlist, 'forecasts', 'pl'))
            line = line.replace('FCSTSL_TABLE_DATA', varTable(vlist, 'forecasts', 'sl'))
            line = line.replace('ANLPL_TABLE_DATA', varTable(vlist, 'analyses', 'pl'))
            line = line.replace('ANLSL_TABLE_DATA', varTable(vlist, 'analyses', 'sl'))
            fdout.write(line)


